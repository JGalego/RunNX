(** Formal specifications for RunNX Tensor operations *)

module TensorSpecs

  use int.Int
  use real.Real
  use array.Array
  use seq.Seq

  (** Abstract tensor type *)
  type tensor = {
    shape: seq int;
    data: array real;
    mutable ghost valid: bool;
  }

  (** Tensor invariants *)
  predicate valid_tensor (t: tensor) =
    t.valid /\
    length t.shape > 0 /\
    (forall i. 0 <= i < length t.shape -> t.shape[i] > 0) /\
    length t.data = fold_left (*) 1 t.shape

  (** Matrix multiplication specification *)
  function matmul_spec (a b: tensor) : tensor
    requires { valid_tensor a /\ valid_tensor b }
    requires { length a.shape = 2 /\ length b.shape = 2 }
    requires { a.shape[1] = b.shape[0] }
    ensures  { valid_tensor result }
    ensures  { length result.shape = 2 }
    ensures  { result.shape[0] = a.shape[0] }
    ensures  { result.shape[1] = b.shape[1] }
    ensures  { length result.data = a.shape[0] * b.shape[1] }

  (** Element-wise addition specification *)
  function add_spec (a b: tensor) : tensor
    requires { valid_tensor a /\ valid_tensor b }
    requires { a.shape = b.shape }
    ensures  { valid_tensor result }
    ensures  { result.shape = a.shape }
    ensures  { length result.data = length a.data }
    ensures  { forall i. 0 <= i < length result.data ->
               result.data[i] = a.data[i] + b.data[i] }

  (** Element-wise multiplication specification *)
  function mul_spec (a b: tensor) : tensor
    requires { valid_tensor a /\ valid_tensor b }
    requires { a.shape = b.shape }
    ensures  { valid_tensor result }
    ensures  { result.shape = a.shape }
    ensures  { length result.data = length a.data }
    ensures  { forall i. 0 <= i < length result.data ->
               result.data[i] = a.data[i] * b.data[i] }

  (** ReLU activation specification *)
  function relu_spec (a: tensor) : tensor
    requires { valid_tensor a }
    ensures  { valid_tensor result }
    ensures  { result.shape = a.shape }
    ensures  { length result.data = length a.data }
    ensures  { forall i. 0 <= i < length result.data ->
               result.data[i] = if a.data[i] > 0.0 then a.data[i] else 0.0 }

  (** Sigmoid activation specification *)
  function sigmoid_spec (a: tensor) : tensor
    requires { valid_tensor a }
    ensures  { valid_tensor result }
    ensures  { result.shape = a.shape }
    ensures  { length result.data = length a.data }
    ensures  { forall i. 0 <= i < length result.data ->
               0.0 < result.data[i] < 1.0 }

  (** Transpose specification for 2D tensors *)
  function transpose_spec (a: tensor) : tensor
    requires { valid_tensor a }
    requires { length a.shape = 2 }
    ensures  { valid_tensor result }
    ensures  { length result.shape = 2 }
    ensures  { result.shape[0] = a.shape[1] }
    ensures  { result.shape[1] = a.shape[0] }
    ensures  { length result.data = length a.data }

  (** Reshape specification *)
  function reshape_spec (a: tensor) (new_shape: seq int) : tensor
    requires { valid_tensor a }
    requires { length new_shape > 0 }
    requires { (forall i. 0 <= i < length new_shape -> new_shape[i] > 0) }
    requires { fold_left (*) 1 new_shape = length a.data }
    ensures  { valid_tensor result }
    ensures  { result.shape = new_shape }
    ensures  { length result.data = length a.data }

end

module TensorProperties

  use TensorSpecs
  use int.Int
  use real.Real

  (** Commutativity of addition *)
  lemma add_commutative:
    forall a b. valid_tensor a -> valid_tensor b -> a.shape = b.shape ->
    add_spec a b = add_spec b a

  (** Associativity of addition *)
  lemma add_associative:
    forall a b c. valid_tensor a -> valid_tensor b -> valid_tensor c ->
    a.shape = b.shape -> b.shape = c.shape ->
    add_spec (add_spec a b) c = add_spec a (add_spec b c)

  (** Identity element for addition (zero tensor) *)
  lemma add_identity:
    forall a zero. valid_tensor a -> valid_tensor zero ->
    a.shape = zero.shape ->
    (forall i. 0 <= i < length zero.data -> zero.data[i] = 0.0) ->
    add_spec a zero = a

  (** Commutativity of multiplication *)
  lemma mul_commutative:
    forall a b. valid_tensor a -> valid_tensor b -> a.shape = b.shape ->
    mul_spec a b = mul_spec b a

  (** Associativity of matrix multiplication *)
  lemma matmul_associative:
    forall a b c. valid_tensor a -> valid_tensor b -> valid_tensor c ->
    length a.shape = 2 -> length b.shape = 2 -> length c.shape = 2 ->
    a.shape[1] = b.shape[0] -> b.shape[1] = c.shape[0] ->
    matmul_spec (matmul_spec a b) c = matmul_spec a (matmul_spec b c)

  (** ReLU properties *)
  lemma relu_idempotent:
    forall a. valid_tensor a ->
    relu_spec (relu_spec a) = relu_spec a

  lemma relu_monotonic:
    forall a b. valid_tensor a -> valid_tensor b -> a.shape = b.shape ->
    (forall i. 0 <= i < length a.data -> a.data[i] <= b.data[i]) ->
    (forall i. 0 <= i < length a.data -> 
     (relu_spec a).data[i] <= (relu_spec b).data[i])

  (** Transpose properties *)
  lemma transpose_involutive:
    forall a. valid_tensor a -> length a.shape = 2 ->
    transpose_spec (transpose_spec a) = a

end
